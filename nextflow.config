/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    GigaAssay config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
    Based on availble config here: https://github.com/nf-core/rnaseq/blob/master/nextflow.config
----------------------------------------------------------------------------------------
*/

// Global default params, used in configs
params {
    // input reads
    //reads =  "$projectDir/data/fastq/SRR*_{1,2}.fastq.gz" // just one sample\
    reads =  "$projectDir/data/fastq/SRR20707784_{1,2}.fastq.gz"

    // output locations
    outdir = "$projectDir/test-run"

    // reference files
    reference = "$projectDir/docs/AF324493.2.fa" //fasta file
    reference_gbk = "AF324493.2" //reference genbank accession no
    bed ="$projectDir/docs/intervals.bed" // genomic interval (0-based) for tat 

    // help & pipeline tracing
    help = false
    tracedir = "$projectDir/pipeline_info"

    // read subsampling
    skip_subsample = null
    samplesize = 0.01

    //trimming
    adapters = "$projectDir/docs/flanks.fa" // file with sequences to trim surrounding Tat contig
    tat_flank_5prime = "GAATTC"
    tat_flank_3prime = "GCGATCGC"
    umi_5prime = 'TGGATCCGGTACCGAGGAGATCTG'
    umi_3prime = 'GCGATCGC'

    //clustering 
    l_distance = 2 // max Levenshtein distance for clustering 

    // scripts used in pipeline are placed in the bin folder
    scripts = "$projectDir/bin"

    // Max resource options
    // Defaults only, expecting to be overwritten
    max_memory                 = '128.GB'
    max_cpus                   = 16
    max_time                   = '240.h'

    tracedir = "$projectDir/pipeline_info"

}

// include the base config file with process resource settings
includeConfig 'conf/base.config'



profiles {

    conda {
        process.conda = "$projectDir/docs/environment_gigaassay.yml"
    }
    conda {
        conda.enabled          = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    mamba {
        conda.enabled          = true
        conda.useMamba         = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }

        docker {
        docker.enabled         = true
        docker.userEmulation   = true
        conda.enabled          = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    arm {
        docker.runOptions = '-u $(id -u):$(id -g) --platform=linux/amd64' // option for runnign on mac m1/m2 machines
    }
    
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        conda.enabled          = false
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }

    standard {
        process.conda          = "$projectDir/docs/environment_gigaassay.yml"
        process.executor = 'local'
    }

    wynton {
        process.executor = 'sge'
        process.queue = 'long'
        process.memory = '10GB'
        process.conda = "$projectDir/docs/environment_gigaassay.yml"
    }

}

// Export this variable to prevent local Python & R libraries from conflicting with those in the container
env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
}

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.html"
}


// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}