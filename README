Try umitools whitelist for barcode extraction rather than cutadapt as will record a csv with the barcode, associated reads 
Maybe first use cutadapt as easier 

Questions:
- proportion of our barcodes that are noise?? num=$(gzip -dc ./230523_0.01_test/clustering/starcode/SRR20707784_starcode_umi_clusters.txt.gz | cut  -f2 | ggrep "[^1]"  | wc -l ); denom=$(gzip -dc ./230523_0.01_test/clustering/starcode/SRR20707784_starcode_umi_clusters.txt.gz | wc -l); echo $num; echo $denom; echo "$num/$denom" | bc -l
  need to run for full sample and perhaps drop clusters with 1 read

-  bed file is 0 based, half =-pne and genbank is 1-based, so have converted bed file
- Why merge reads prior to trimming adapters? for length filtering
- demultiplex script & how to handle I/O bottleneck from number of reads... could we just discard reads that don't match barcode? So much data as is..
- Need to find way to filter reads if the barcodes are shorter than 32bp before processing to speed up
- OUtput that we need
- Could maybe create a barcode file from clustering results?

Outputs:
- BBmerge merging ~80% of reads, 92% with flask, but maybe higher quality results?
- less reads recovered in the umi-tools extract function (~10%)
- Changes Levinstein distance to 4 so less clusters to cycle through

Notes:
- The Tat reference sequence includes the 32bp N for barcode matching
- If demultiplexing, need to first combine all files and then demultiplex
- pipeline took two hours to run with 10k reads for 3x samples... may need to drop some of the processes
- instead of splitting files like this, could we add consensus barcode to read header and retain this information in bam file? if the samples are different, then we could call variants on the bam and just write to csv...


Used info here to create my own custom db
https://www.biostars.org/p/432180/

24/05/23
----
Testing UMI-tools whitelist on the subsampled files to identify cell barcodes. Compare with other clustering tools
If using run on merge rather than trimmed reads
umi_tools whitelist --method 'reads' --knee-method "density" --error-correct-threshold --plot-prefix 'test.out.umitools' --ed-above-threshold 'discard' --extract-method=regex --bc-pattern='.+(?P<discard_1>TGGATCCGGTACCGAGGAGATCTG){s<=2}(?P<cell_1>.{32}){s<=2}(?P<discard_2>GCGATCGC.+)$
Even with full file, only 40% of the reads have more than one member of the


#SNPeff dependencies, configs is stored under /Users/martingordon/anaconda3/envs/gigaassay/share/snpeff-5.1-2
# added HIV-1 to the config file

16/08/23
---
Testing the pipelin with minimal number of reads
Mainly we want to see how the vcf merging works; think we were filtering reads that were incoreect size


25/09/23
----
Issue with nextflow process when generating large number of files: see slack issue for details: https://nextflow.slack.com/archives/C02T98A23U7/p1695673765111919
Solution for now is to compress output in dir and move that around, then iterate through the files in each work dir

04/10/23
----
Pipeline running successfully, up to the concatenation step
Failed due to large number of files loaded; retry tomorrow to complete the test
Now just need to split the directory of vcfs into batches, loop through those 

test nf-pipeline with script in test dir
remember to set the tmpdirectory when executing

TODO
---
Modularise the pipeline

To do 
--
Write a script to add the sample name to the read header

Completed script to add headers to the merged reads - test the pipeline

Added the combined file to the channels to pass around processes. Now need to write py script to demux files belonging to different samples
Use seqkit grep for extracting the fastq from each file, how to get sample names? too long to search within fastq, so instead pass the cat command to
Using the bbmap tool for this as faster 


## 
example command used to run the file and this works in isolation:
singularity exec -B "/wynton/group/krogan/mgordon/projects" /wynton/group/krogan/mgordon/src/singularity/depot.galaxyproject.org-singularity-bbmap-39.01--h5c4e2a8_0.img demuxbyname.sh in=TCCACGGAGAGCACACACAACACCCTAAGAAA_combined_samples.demux.fastq.gz out=test_%_.fastq.gz prefixmode=f names=work/40/2a30c598befa0bb9539c5c53df3d89/sampleID.txt

now looks to be running.. now take the output and split into 4 channels; one per folder/sample


#TODO
looks good; test on full set of data
keep an eye on variant calling params; maybe better to call everything then filter downstream?
improvement: write python script to take in output of clustering and clustering barcode, search for the then demux by name?
within the sample level, could we look at batching to process in parallel? for example split each sample into 10 groups of equally sized batches and submit to the subsequent processes?
may be issues with the bash limits and argument sizes (ls etc..), but if subdividing into say 10-100 batches per sample, perhaps not an issue.. would solving this reduce the runtime?