Try umitools whitelist for barcode extraction rather than cutadapt as will record a csv with the barcode, associated reads and the number of times the barcode was detected (think it was 4 levinstein distance for ) 
Maybe first use cutadapt as easier 

Questions:
- trim reads of final 32bp after barcode matching
- Why not remove duplicates?
- Why merge reads prior to trimming adapters?
- Starcode cluster params
- demultiplex script & how to handle I/O bottleneck from number of reads... could we just discard reads that don't match barcode? So much data as is..


Outputs:
- BBmerge merging ~80% of reads, 92% with flask, but maybe higher quality results?
- less reads recovered in the umi-tools extract function (~10%)
- Changes Levinstein distance to 4 so less clusters to cycle through
